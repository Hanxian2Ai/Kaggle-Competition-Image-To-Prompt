## Bronze Medal Solution For Kaggle Complete : Stable Diffusion - Image to Prompts

kaggleä¸»é¡µ :  https://www.kaggle.com/hanxian0820

ä¸ªäººæˆç»©ï¼š**Top8% é“œç‰Œ**  ğŸ¥‰ğŸ¥‰ğŸ¥‰

**èµ›é¢˜ä»‹ç»ï¼š**

â€‹	æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„æµè¡Œæ˜¯å…¨æ–°çš„æç¤ºå·¥ç¨‹é¢†åŸŸã€‚ä¸€éƒ¨åˆ†æ˜¯è‰ºæœ¯ï¼Œä¸€éƒ¨åˆ†æ˜¯æ‚¬è€Œæœªå†³çš„ç§‘å­¦ï¼Œæœºå™¨å­¦ä¹ ä»ä¸šè€…å’Œç ”ç©¶äººå‘˜æ­£åœ¨è¿…é€ŸåŠªåŠ›ç†è§£æç¤ºä¸å…¶ç”Ÿæˆçš„å›¾åƒä¹‹é—´çš„å…³ç³»ã€‚

â€‹	å°†â€œ4kâ€æ·»åŠ åˆ°æç¤ºä¸­æ˜¯ä½¿å…¶æ›´å…·æ‘„å½±æ€§çš„æœ€ä½³æ–¹å¼å—ï¼Ÿæç¤ºä¸­çš„å°æ‰°åŠ¨ä¼šå¯¼è‡´é«˜åº¦ä¸åŒçš„å›¾åƒå—ï¼Ÿæç¤ºå…³é”®å­—çš„é¡ºåºå¦‚ä½•å½±å“ç”Ÿæˆçš„åœºæ™¯ï¼Ÿæœ¬æ¬¡æ¯”èµ›çš„ä»»åŠ¡æ˜¯åˆ›å»ºä¸€ä¸ªæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥å¯é åœ°åè½¬ç”Ÿæˆç»™å®šå›¾åƒçš„æ‰©æ•£è¿‡ç¨‹ã€‚

â€‹	ä¸ºäº†ä»¥ç¨³å¥çš„æ–¹å¼è®¡ç®—æç¤ºç›¸ä¼¼åº¦ï¼Œè¿™æ„å‘³ç€å°½ç®¡å­—ç¬¦çº§åˆ«å­˜åœ¨å·®å¼‚ã€‚æœ¬æ¬¡æ¯”èµ›å¸Œæœ›åˆ›å»ºâ€œé«˜è´¨é‡ã€ä¸“æ³¨ã€å¤æ‚ã€è¯¦ç»†ã€å…·æœ‰ä¸çœŸå®çš„ç¨³å¥äº¤å‰éªŒè¯é£æ ¼â€çš„æ¨¡å‹ã€‚

**æ¯”èµ›ä»»åŠ¡ï¼š**

1ã€æœ¬æ¬¡æ¯”èµ›çš„ç›®æ ‡æ˜¯æ‰­è½¬ç”Ÿæˆæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„å…¸å‹æ–¹å‘ï¼šä¸æ˜¯ä»æ–‡æœ¬æç¤ºç”Ÿæˆå›¾åƒï¼Œè€Œæ˜¯å¯ä»¥åˆ›å»ºä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹ç»™å®šç”Ÿæˆå›¾åƒçš„æ–‡æœ¬æç¤ºã€‚å‚èµ›é€‰æ‰‹éœ€è¦å¯¹åŒ…å«ç”± Stable Diffusion 2.0 ç”Ÿæˆçš„å„ç§ï¼ˆæç¤ºã€å›¾åƒï¼‰å¯¹çš„æ•°æ®é›†è¿›è¡Œé¢„æµ‹ï¼Œä»¥äº†è§£æ½œåœ¨å…³ç³»çš„å¯é€†æ€§ã€‚

2ã€æ¨æ–­ç”Ÿæˆé«˜åº¦è¯¦ç»†ã€æ¸…æ™°çš„ç„¦ç‚¹ã€æ’å›¾ã€å®ä¼Ÿã€å²è¯—èˆ¬çš„ 3d æ¸²æŸ“å›¾åƒçš„prompt

##### è§£å†³æ–¹æ¡ˆï¼š
![](https://github.com/Hanxian2Ai/image2prompt/blob/main/md_image/Snipaste_2023-05-19_21-57-49.png)

- æ•°æ®æ”¶é›†ã€ç”Ÿæˆå’Œæ¸…ç†ï¼ˆ38wï¼‰

  - DiffusionDB 200 ä¸‡å›¾åƒæç¤ºå­é›†æ•°æ®é›†ï¼šhttps://poloclub.github.io/diffusiondb/
  - æ–‡æœ¬æç¤ºç¬¦è¿›è¡Œæ¸…æ´—ï¼šå»é‡ã€é•¿åº¦ç­›é€‰ã€å­—ç¬¦ç­›é€‰ã€è¯­ä¹‰ç›¸ä¼¼åº¦ç­›é€‰
  - åˆ é™¤é‡å¤çš„æ–‡æœ¬åŠå…¶å›¾ç‰‡ï¼šè®¡ç®—ç›¸ä¼¼åº¦ ä½¿ç”¨å‘é‡æœç´¢åº“**faiss-gpu**

- model

  - é€‰æ‹©CLIPæ¨¡å‹ä½œä¸ºåŸºå‡†æ¨¡å‹ï¼ŒåŒ…æ‹¬clip-vit-large-224å’Œclip-vit-large-336
  - åŠ ä¸€å±‚å…¨è¿æ¥å±‚ï¼Œè¾“å‡ºï¼ˆ1ï¼Œ384ï¼‰ç»´çš„embedding

  ```python
  class Net(nn.Module):
      def __init__(self):
          super(Net, self).__init__()
          clip = AutoModel.from_pretrained("clip-vit-224")
          self.vision = clip.vision_model
          self.fc = nn.Linear(1024, 384)
         	#1st solution
          nn.init.xavier_uniform_(self.fc.weight)
  
  
      def forward(self, x):
          x = self.vision(x)['pooler_output']
          x = self.fc(x)
          return x
  ```

  - ç¬¬ä¸€åè§£å†³æ–¹æ¡ˆï¼Œåœ¨æœ€åçš„è¾“å‡ºå±‚å‰åŠ ä¸€å±‚å¤§çš„å…¨è¿æ¥å±‚


  ```python
    ebd_dim = 1024
    fc_dim = 16 * 1024
    self.head = nn.Sequential(
      nn.Linear(ebd_dim, fc_dim),
      nn.BatchNorm1d(fc_dim),
      nn.ReLU(),
      nn.Linear(fc_dim, 384),
    )
  ```

- æ•°æ®å¢åŠ 

  - Mixgen([Mixgen: A new multi-modal data augmentation](https://openaccess.thecvf.com/content/WACV2023W/Pretrain/html/Hao_MixGen_A_New_Multi-Modal_Data_Augmentation_WACVW_2023_paper.html))
  ![](https://github.com/Hanxian2Ai/image2prompt/blob/main/md_image/Snipaste_2023-05-21_19-59-15.png)
  - RandomHorizontalFlip(0.5)

- è®­ç»ƒç­–ç•¥

  - [Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution](https://arxiv.org/abs/2202.10054) å…ˆåªè®­ç»ƒæœ€åä¸€å±‚çº¿æ€§è¿æ¥å±‚ï¼Œç„¶åå†æ•´ä¸ªæ¨¡å‹è¿›è¡Œå¾®è°ƒ
  ![](https://github.com/Hanxian2Ai/image2prompt/blob/main/md_image/Snipaste_2023-05-21_20-00-28.png)

- æ¨ç†ç­–ç•¥

  - TTA

    ```python
    def predict(images,
        model_path,
        model_name,
        input_size,
        batch_size
    ):   
        tta_preds = None
        for _ in range(2):
            preds = []
            for X in tqdm(dataloader, leave=False):
                X = X.to(device)
    
                with torch.no_grad():
                    X_out = model(X).cpu().numpy()
                    # L2 normalize -- Start
                    X_out = X_out / ( np.abs(X_out).max(axis=-1, keepdims=True) + 1e-8)  
                    X_out = normalize( X_out )
                    # L2 normalize -- End
                    preds.append(X_out)
                    
            if tta_preds is None:
                tta_preds = np.vstack(preds).flatten()
            else:
                tta_preds += np.vstack(preds).flatten()
        
        return tta_preds / 2
    ```

    

  - æ¨¡å‹èåˆ

    ```python
    class WeightedAverage(nn.Module):
        def __init__(self, n):
            super().__init__()
            self.weight = nn.Linear(n, 1, bias=False)
            with torch.no_grad():
                self.weight.weight[:] = 1.0
    
        def forward(self, x, y):
            y_hat = self.weight(x)[..., 0]
            y_hat = torch.nn.functional.normalize(y_hat, dim=-1)
            cos_sim = (y * y_hat).sum(dim=-1)
            loss = -cos_sim.mean()
            return loss
    ```

    



